{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Chowda","text":"<p>A CLAMS processing app</p>"},{"location":"#install","title":"Install","text":"<p>Install instructions can be found on the install page</p>"},{"location":"#reference","title":"Reference","text":"<p>Further details can be found in the reference section</p>"},{"location":"#credits","title":"Credits","text":"<p>Created by WGBH-MLA for the CLAMS project</p>"},{"location":"install/","title":"Install","text":""},{"location":"install/#clone-the-repository","title":"Clone the repository::","text":"<pre><code>git clone https://github.com/WGBH-MLA/chowda.git\ncd chowda\n</code></pre>"},{"location":"install/#install-with-pdm-recommended","title":"Install with PDM (Recommended)","text":"<p>PDM is used as the packaging manager. It can be installed with <code>pip install pdm</code>.</p> <p>Install the project with development dependencies:</p> <pre><code>pdm install\n</code></pre> <p>Activate your virtual environment</p> <pre><code>$(pdm venv activate)\n</code></pre> <p>Note: <code>pdm venv activate</code> outputs the command needed to activate your virtual environment. The <code>$()</code> wrapper evaluates it in your current shell context.</p>"},{"location":"install/#install-with-venv","title":"Install with venv","text":"<p>If PDM is not available, it can also be installed with pip. It is recommeneded to install to a virtual environment using <code>venv</code>:</p> <pre><code>python3 -m venv .venv\nsource .venv/bin/activate\n</code></pre> <p>Install the package</p> <pre><code>pip install .\n</code></pre>"},{"location":"install/#create-postgresql-database-and-start-the-database-server","title":"Create PostgreSQL database and start the database server","text":"<p>Chowda needs to have a PostgreSQL server running and database named <code>chowda-development</code> (tests use a database <code>chowda-test</code>).</p> <p>There are many ways to do this, but an easy way is to use docker. After starting Docker on your local machine, the following command will start a container using the <code>postgres</code> image in Dockerhub.</p> <pre><code>docker run --rm --name pg -p 5432:5432 -e POSTGRES_USER=postgres -e POSTGRES_PASSWORD=postgres -e POSTGRES_DB=chowda-development postgres\n</code></pre>"},{"location":"install/#command-explained","title":"Command explained","text":"<ul> <li><code>docker run</code> runs a docker container</li> <li><code>--rm</code> option will remove the docker container once it exits.</li> <li><code>--name pg</code> will name the running container <code>pg</code> so it can be identified when listing running containers.</li> <li><code>-p 5432:5432</code> forwards port 5432 on your local machine to port 5432 (default postgres port) on the running container.</li> <li><code>-e POSTGRES_USER=postgres</code> sets ENV var on container for the postgres username</li> <li> <p><code>-e POSTGRES_PASSWORD=postgres</code> sets ENV var on container for postgres password</p> <p>Note</p> <p>Not a secure password, but that's ok for test and development environments.</p> </li> <li> <p><code>-e POSTGRES_DB=chowda-development</code> sets ENV var on container for the name of postgres database to use</p> <p>Note</p> <p>The <code>postgres</code> image will create the database when starting the container.</p> </li> <li> <p><code>postgres</code> is the name of the Docker image to use when starting the container.</p> </li> </ul> <p>Note</p> <p>the environment variables values in the command must match the values that are part of the <code>DB_URL</code> environment variable specified in <code>.env.development</code>.</p>"},{"location":"install/#run-database-migrations-with-alembic","title":"Run database migrations with Alembic","text":"<pre><code>alembic upgrade head\n</code></pre>"},{"location":"install/#run-the-application","title":"Run the application","text":"<pre><code>uvicorn chowda:app --reload\n</code></pre> <p>Visit: localhost:8000</p>"},{"location":"install/#seed-the-database","title":"Seed the database","text":"<p>To seed the database with fake data, run the <code>seeds.py</code> script:</p> <pre><code>python tests/seeds.py\n</code></pre> <p>Optional: Customize the number of records created by changing the <code>num_*</code> variables in the <code>seed</code> function.</p>"},{"location":"install/#running-tests","title":"Running tests","text":"<p>Chowda uses <code>pytest</code> for testing.</p>"},{"location":"install/#creating-the-test-database-and-running-a-postgres-server","title":"Creating the test database and running a postgres server","text":"<p>This is done the same way as in the development environment (see above), only the database name is changed. <pre><code>docker run --rm --name pg -p 5432:5432 -e POSTGRES_USER=postgres -e POSTGRES_PASSWORD=postgres -e POSTGRES_DB=chowda-development postgres\n</code></pre></p>"},{"location":"install/#running-the-tests-from-terminal","title":"Running the tests from terminal","text":"<pre><code>pytest --vcr-record=none --nbmake\n</code></pre>"},{"location":"install/#deactivate-the-virtual-environment","title":"Deactivate the virtual environment","text":"<p>Run the <code>deactivate</code> command to return to your normal shell environment.</p> <pre><code>deactivate\n</code></pre>"},{"location":"examples/__init__/","title":"init","text":""},{"location":"examples/events/","title":"Events","text":"In\u00a0[1]: Copied! <pre>from metaflow.integrations import ArgoEvent\n\nsync = ArgoEvent('sync')\n\n# trigger the event with publish()\n# sync.publish()\n</pre> from metaflow.integrations import ArgoEvent  sync = ArgoEvent('sync')  # trigger the event with publish() # sync.publish()"},{"location":"examples/events/#events","title":"Events\u00b6","text":"<p>Use Argo Events to trigger workflows.</p>"},{"location":"examples/events/#setup","title":"Setup\u00b6","text":"<p>Configure Metaflow to connect to Argo Events.</p> <pre>{\n\"METAFLOW_ARGO_EVENTS_EVENT\": \"chowda\",\n\"METAFLOW_ARGO_EVENTS_EVENT_BUS\": \"default\",\n\"METAFLOW_ARGO_EVENTS_EVENT_SOURCE\": \"webhook\",\n\"METAFLOW_ARGO_EVENTS_INTERNAL_WEBHOOK_URL\": \"http://webhook-eventsource-svc.argo-events.svc.cluster.local:12000\",\n\"METAFLOW_ARGO_EVENTS_WEBHOOK_URL\": \"http://localhost:12000/chowda\",\n\"METAFLOW_ARGO_EVENTS_SERVICE_ACCOUNT\": \"operate-workflow-sa\",\n...\n}\n</pre> <p>If running locally, port-forward the webhook event source.</p> <pre>kubectl port-forward svc/webhook-eventsource-svc 12000:12000\n</pre>"},{"location":"examples/events/#sync","title":"Sync\u00b6","text":"<p>Trigger the <code>IngestFlow</code> to sync all assets from SonyCi to the Chowda database.</p>"},{"location":"examples/session/","title":"SQLModel Session exercise","text":"In\u00a0[1]: Copied! <pre>from chowda.db import init_db\nfrom tests.factories import *\ninit_db()\n</pre> from chowda.db import init_db from tests.factories import * init_db() In\u00a0[2]: Copied! <pre>batch = BatchFactory.create()\n</pre> batch = BatchFactory.create() In\u00a0[3]: Copied! <pre>from sqlmodel import Session\n\nsession = Session.object_session(batch)\n</pre> from sqlmodel import Session  session = Session.object_session(batch) In\u00a0[4]: Copied! <pre>batch.description = \"exceedingly jolly\"\n</pre> batch.description = \"exceedingly jolly\" In\u00a0[5]: Copied! <pre>print('session.dirty = ', session.dirty)\n# =&gt; session.dirty = IdentitySet([Batch(description='foo')])\n</pre> print('session.dirty = ', session.dirty) # =&gt; session.dirty = IdentitySet([Batch(description='foo')]) <pre>session.dirty =  IdentitySet([Batch(description='exceedingly jolly')])\n</pre> In\u00a0[6]: Copied! <pre>session.commit()\n</pre> session.commit() In\u00a0[7]: Copied! <pre>print('session.dirty = ', session.dirty)\n# =&gt; IdentitySet([])\n</pre> print('session.dirty = ', session.dirty) # =&gt; IdentitySet([]) <pre>session.dirty =  IdentitySet([])\n</pre> In\u00a0[19]: Copied! <pre>from sqlmodel import select\n\nwith Session(engine) as db:\n    batch_copy = db.exec(select(Batch).where(Batch.id == batch.id)).first()\nprint('batch_copy.description = ', batch_copy.description)\n# =&gt; foo\n</pre> from sqlmodel import select  with Session(engine) as db:     batch_copy = db.exec(select(Batch).where(Batch.id == batch.id)).first() print('batch_copy.description = ', batch_copy.description) # =&gt; foo <pre>batch_copy.description =  exceedingly jolly and effortlessly charming and elaborately loquacious\n</pre> <p>Note that since we grabbed batch_copy using a contextual session, and that context has ended, so has the session, and the object is currently unattached to any session.</p> In\u00a0[20]: Copied! <pre>print('seesion for batch_copy = ', Session.object_session(batch_copy))\n# =&gt; None\n</pre> print('seesion for batch_copy = ', Session.object_session(batch_copy)) # =&gt; None <pre>seesion for batch_copy =  None\n</pre> In\u00a0[12]: Copied! <pre>batch_copy.description += \" and effortlessly charming\"\nwith Session(engine) as db:\n    db.add(batch_copy)\n    db.commit()\n</pre> batch_copy.description += \" and effortlessly charming\" with Session(engine) as db:     db.add(batch_copy)     db.commit()  In\u00a0[13]: Copied! <pre>with Session(engine) as db:\n    db.add(batch_copy)\n    print('batch_copy.description = ', batch_copy.description)\n    # =&gt; batch_copy.description =  exceedingly jolly and effortlessly charming\n</pre> with Session(engine) as db:     db.add(batch_copy)     print('batch_copy.description = ', batch_copy.description)     # =&gt; batch_copy.description =  exceedingly jolly and effortlessly charming  <pre>batch_copy.description =  exceedingly jolly and effortlessly charming\n</pre> In\u00a0[14]: Copied! <pre>print('batch.description before refresh = ', batch.description)\n# =&gt; batch.description before refresh = exceedingly jolly\n</pre> print('batch.description before refresh = ', batch.description) # =&gt; batch.description before refresh = exceedingly jolly  <pre>batch.description before refresh =  exceedingly jolly\n</pre> In\u00a0[15]: Copied! <pre>session.refresh(batch)\nprint('batch.description after refresh = ', batch.description)\n# =&gt; batch.description after refresh = exceedingly jolly and effortlessly charming\n</pre> session.refresh(batch) print('batch.description after refresh = ', batch.description) # =&gt; batch.description after refresh = exceedingly jolly and effortlessly charming  <pre>batch.description after refresh =  exceedingly jolly and effortlessly charming\n</pre> In\u00a0[16]: Copied! <pre>batch.description += \" and fantastically flatulent\"\n</pre> batch.description += \" and fantastically flatulent\" In\u00a0[17]: Copied! <pre>session.commit()\n</pre> session.commit()  In\u00a0[18]: Copied! <pre>with Session(engine) as db:\n    batch_copy.description += \" and elaborately loquacious\"\n    db.add(batch_copy)\n    db.commit()\n    print('batch_copy.description = ', batch_copy.description)\n# =&gt; batch_copy.description =  exceedingly jolly and effortlessly charming and elaborately loquacious\n</pre> with Session(engine) as db:     batch_copy.description += \" and elaborately loquacious\"     db.add(batch_copy)     db.commit()     print('batch_copy.description = ', batch_copy.description) # =&gt; batch_copy.description =  exceedingly jolly and effortlessly charming and elaborately loquacious  <pre>batch_copy.description =  exceedingly jolly and effortlessly charming and elaborately loquacious\n</pre>"},{"location":"examples/session/#sqlmodel-session-exercise","title":"SQLModel Session exercise\u00b6","text":"<p>Adapted from Drew's slack example</p>"},{"location":"examples/session/#create-a-new-batch-from-factory","title":"Create a new Batch from factory\u00b6","text":""},{"location":"examples/session/#grab-the-session-the-batch-was-created-with-for-inspection","title":"Grab the session the Batch was created with for inspection.\u00b6","text":""},{"location":"examples/session/#change-something-on-the-batch","title":"Change something on the batch\u00b6","text":""},{"location":"examples/session/#view-the-changes-that-have-yet-to-be-committed-to-the-db","title":"View the changes that have yet to be committed to the db\u00b6","text":""},{"location":"examples/session/#commit-the-changes-to-the-db","title":"Commit the changes to the db.\u00b6","text":"<p>Note that we do not have to call session.add(batch) since the Batch instance is already attached to the session.</p>"},{"location":"examples/session/#verify-there-are-no-other-pending-changes","title":"Verify there are no other pending changes.\u00b6","text":""},{"location":"examples/session/#use-a-contextual-session","title":"Use a contextual session\u00b6","text":"<p>(called \"db\") to grab a separate copy of the batch and verify it has the change.</p>"},{"location":"examples/session/#now-change-batch_copydescripiton","title":"Now change batch_copy.descripiton,\u00b6","text":"<p>save it with a contextual session, and see how it affected or original Batch instance, which is still alive and attached to the session it was created with.</p>"},{"location":"examples/session/#note-after-committing-changes-to-batch_copy-using-contextual-session-in-this-way","title":"NOTE: after committing changes to batch_copy using contextual session in this way,\u00b6","text":"<p>trying to access attributes on the object like batch_copy.description raises an error:</p> <p>Instance &lt;Batch at 0x107b84e10&gt; is not bound to a Session; attribute refresh operation cannot proceed</p>"},{"location":"examples/session/#confirm-that-our-original-batch-instance-still-has-the-old-description","title":"Confirm that our original Batch instance still has the old description\u00b6","text":""},{"location":"examples/session/#refresh-the-original-batch-instance","title":"Refresh the original Batch instance\u00b6","text":"<p>and check the description again</p>"},{"location":"examples/session/#now-lets-edit-batchdescription-and-batch_copydescription","title":"Now let's edit <code>batch.description</code> and <code>batch_copy.description</code>\u00b6","text":"<p>and update them both independently to see what happens.</p>"},{"location":"examples/session/#save-the-first-edit","title":"save the first edit\u00b6","text":""},{"location":"examples/session/#save-the-second-edit","title":"save the second edit\u00b6","text":""},{"location":"examples/session/#unsurprisingly-the-2nd-save-wins","title":"Unsurprisingly, the 2nd save wins.\u00b6","text":"<p>The changes saved in original Batch instance with it's original session get overwritten by this one.</p>"},{"location":"examples/upsert/","title":"Upsert","text":"In\u00a0[1]: Copied! <pre>from sqlmodel import Session, select\n\nfrom chowda.models import SonyCiAsset\nfrom chowda.db import engine\n</pre> from sqlmodel import Session, select  from chowda.models import SonyCiAsset from chowda.db import engine In\u00a0[2]: Copied! <pre>def get_asset():\n    with Session(engine) as session:\n        z = session.exec(select(SonyCiAsset).where(SonyCiAsset.id == 'test'))\n\n        x = z.first()\n</pre> def get_asset():     with Session(engine) as session:         z = session.exec(select(SonyCiAsset).where(SonyCiAsset.id == 'test'))          x = z.first()  In\u00a0[3]: Copied! <pre>from sqlalchemy.dialects.postgresql import insert\n\nc = SonyCiAsset(\n    id='test',\n    name='testname',\n    type='Video',\n    size=1,\n    format='mp4',\n    thumbnails=[],\n)\nc.dict()\n</pre> from sqlalchemy.dialects.postgresql import insert  c = SonyCiAsset(     id='test',     name='testname',     type='Video',     size=1,     format='mp4',     thumbnails=[], ) c.dict()  Out[3]: <pre>{'name': 'testname',\n 'size': 1,\n 'type': &lt;MediaType.video: 'Video'&gt;,\n 'format': 'mp4',\n 'thumbnails': []}</pre> In\u00a0[4]: Copied! <pre>def upsert(asset):\n    with Session(engine) as session:\n        stmt = (\n            insert(SonyCiAsset)\n            .values([asset])\n            .on_conflict_do_update(\n                index_elements=[SonyCiAsset.id],\n                set_=asset,\n            )\n        )\n        session.execute(stmt)\n        session.commit()\n</pre> def upsert(asset):     with Session(engine) as session:         stmt = (             insert(SonyCiAsset)             .values([asset])             .on_conflict_do_update(                 index_elements=[SonyCiAsset.id],                 set_=asset,             )         )         session.execute(stmt)         session.commit()"},{"location":"reference/","title":"Reference","text":"<p>This section describes the implementation of specific code modules.</p>"},{"location":"reference/#modules","title":"Modules","text":"<ul> <li>app - the main web application</li> <li>models - Database models</li> </ul>"},{"location":"reference/app/","title":"App","text":"<p>App</p> <p>Main Chowda application</p>"},{"location":"reference/database/","title":"Database Management","text":""},{"location":"reference/database/#migrations-with-alembic","title":"Migrations with Alembic","text":"<p>Chowda uses Alembic, a migration tool for the SQLAlchemy, which is the database ORM used by SQLModel.</p>"},{"location":"reference/database/#creating-migrations","title":"Creating migrations","text":"<p>Chowda's models inherit from <code>SQLModel</code> and if the <code>table=True</code> parameter is passed, then the model is for representing data stored in a database table. For these models to work correctly, the underlying table needs to match the <code>SQLModel</code> definition in python code, and this is where migrations come in.</p> <p>Alembic can detect the differences between Chowda's models and the underlying databse schema and then generate a migration script to change the database to match the model.</p> <p>After you have made the changes to your model classes, run the following command from the command line: <pre><code>alembic revision --autogenerate -m \"short_desc_of_model_changes\"\n</code></pre> This will generate a migration script under <code>migrations/revision</code>. The script name will be an random ID for the revision followed by the value of the <code>-m</code> flag, e.g.  <code>480b8fe17026_short_desc_of_db_change.py</code>.</p> <p>NOTE: After a migration is run, the revision ID in the file name is stored in the <code>alembic_version</code> table that is added to the database when Alembic is first installed. This table is what tells Alembic whether there are migrations to run or not.</p>"},{"location":"reference/database/#checking-to-see-if-there-are-any-migrations-to-run","title":"Checking to see if there are any migrations to run","text":"<p>From the command line run: <pre><code>alembic check\n</code></pre> If there are no migrations to run, you should see: <pre><code>No new upgrade operations detected.\n</code></pre> If there are migrations to run, you should see: <pre><code>ERROR [alembic.util.messaging] Target database is not up to date.\n  FAILED: Target database is not up to date.\n</code></pre></p>"},{"location":"reference/database/#run-migrations","title":"Run migrations","text":"<p>From the command line run: <pre><code>alembic upgrade head\n</code></pre> This will run all migrations that haven't yet been run. If there were no migrations that needed to run, nothing will happen.</p>"},{"location":"reference/models/","title":"Models","text":"<p>Models</p> <p>SQLModels for DB and validation</p>"},{"location":"reference/models/#chowda.models.MediaUrl","title":"<code>MediaUrl = stricturl(allowed_schemes=['video', 'audio', 'text'], tld_required=False)</code>  <code>module-attribute</code>","text":"<p>Media url validator. Must have prefix of video, audio, or text. No TLD required.</p> Example <p>video://*</p>"},{"location":"reference/models/#chowda.models.MediaFile","title":"<code>MediaFile</code>","text":"<p>             Bases: <code>SQLModel</code></p> <p>Media file model</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>Optional[int]</code> <p>SonyCi asset id</p> <code>guid</code> <code>str</code> <p>asset guid</p> Source code in <code>chowda/models.py</code> <pre><code>class MediaFile(SQLModel, table=True):\n\"\"\"Media file model\n\n    Attributes:\n        id: SonyCi asset id\n        guid: asset guid\n    \"\"\"\n\n    __tablename__ = 'media_files'\n    id: Optional[int] = Field(primary_key=True, default=None)\n    guid: str = Field(index=True)\n    mmif_json: Dict[str, Any] = Field(sa_column=Column(JSON), default=None)\n    collections: List['Collection'] = Relationship(\n        back_populates='media_files', link_model=MediaFileCollectionLink\n    )\n    batches: List['Batch'] = Relationship(\n        back_populates='media_files', link_model=MediaFileBatchLink\n    )\n    clams_events: List['ClamsEvent'] = Relationship(back_populates='media_file')\n\n    async def __admin_repr__(self, request: Request):\n        return self.guid\n\n    async def __admin_select2_repr__(self, request: Request) -&gt; str:\n        return f'&lt;span&gt;&lt;strong&gt;{self.guid}&lt;/strong&gt;&lt;/span&gt;'\n</code></pre>"},{"location":"reference/models/#chowda.models.User","title":"<code>User</code>","text":"<p>             Bases: <code>SQLModel</code></p> <p>User model</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>Optional[int]</code> <p>Primary key</p> <code>email</code> <code>EmailStr</code> <p>User email</p> <code>first_name</code> <code>str</code> <p>User first name</p> <code>last_name</code> <code>str</code> <p>User last name</p> Source code in <code>chowda/models.py</code> <pre><code>class User(SQLModel, table=True):\n\"\"\"User model\n\n    Attributes:\n        id: Primary key\n        email: User email\n        first_name: User first name\n        last_name: User last name\n    \"\"\"\n\n    __tablename__ = 'users'\n    id: Optional[int] = Field(primary_key=True)\n    email: EmailStr = Field(index=True)\n    first_name: str = Field(min_length=3, index=True)\n    last_name: str = Field(min_length=3, index=True)\n\n    async def __admin_repr__(self, request: Request):\n        return f'{self.first_name} {self.last_name}'\n</code></pre>"}]}